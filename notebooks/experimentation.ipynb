{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flash as fz\n",
    "import joblib\n",
    "import klib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    OneHotEncoder,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Assessment and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/raw/loan_sanction_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand structure of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless features\n",
    "useless_features = [\"Loan_ID\"]\n",
    "df.drop(columns=useless_features, inplace=True)\n",
    "\n",
    "# Test\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "df = klib.clean_column_names(df)\n",
    "\n",
    "# Test\n",
    "column_names = df.columns.tolist()\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate data points\n",
    "def check_duplicates(df):\n",
    "    if df.duplicated().any():\n",
    "        return df[df.duplicated(keep=False)]\n",
    "    return \"There are no duplicate data points in the dataset.\"\n",
    "\n",
    "\n",
    "check_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical, categorical, and other features from the dataset\n",
    "num_cols, cat_cols, other_cols = fz.extract_features(\n",
    "    df, \"all\", ignore_cols=[\"loan_status\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print numerical features of dataset\n",
    "df[num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print categorical features of dataset\n",
    "df[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dependents\"] = df[\"dependents\"].str.replace(r\"\\+$\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"loan_status\"] = df[\"loan_status\"].replace({\"Y\": \"yes\", \"N\": \"no\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datatype of features\n",
    "# df['applicant_income'] = df['applicant_income'].astype(float)\n",
    "df[\"dependents\"] = df[\"dependents\"].astype(\"Int64\")\n",
    "df[\"loan_amount_term\"] = df[\"loan_amount_term\"].astype(\"Int64\")\n",
    "df[\"credit_history\"] = df[\"credit_history\"].astype(\"Int64\")\n",
    "# Convert categorical features' data type to category\n",
    "# This will be helpful while doing analysis\n",
    "df[cat_cols] = df[cat_cols].astype(\"category\")\n",
    "\n",
    "# Test\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features\n",
    "num_nan_pct = fz.calc_nan_values(df[num_cols])\n",
    "num_cols_with_nan = num_nan_pct.index.tolist()\n",
    "\n",
    "print(num_nan_pct)  # Percentage of missing values in numerical features\n",
    "print(num_cols_with_nan)  # Numerical features with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "cat_nan_pct = fz.calc_nan_values(df[cat_cols])\n",
    "cat_cols_with_nan = cat_nan_pct.index.tolist()\n",
    "\n",
    "print(cat_nan_pct)  # Percentage of missing values in categorical features\n",
    "print(cat_cols_with_nan)  # Categorical features with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the target column contains any missing values\n",
    "df[\"loan_status\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of missing values to determine the type of missing values\n",
    "fig, axs = fz.nan_value_viz(df[num_cols_with_nan + cat_cols_with_nan])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical measures\n",
    "df[num_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical moments\n",
    "fz.stats_moments(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histogram & boxplot\n",
    "fig, axs = fz.hist_box_viz(df[num_cols])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical measures\n",
    "df[cat_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplots\n",
    "fig, axs = fz.count_viz(df[cat_cols])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"loan_status\"].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(\n",
    "    df[\"loan_status\"].value_counts(),\n",
    "    labels=df[\"loan_status\"].unique(),\n",
    "    autopct=\"%0.2f%%\",\n",
    "    shadow=True,\n",
    "    explode=(0, 0.1),\n",
    "    counterclock=False,\n",
    "    colors=[\"lime\", \"cyan\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vs. Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "grid = fz.pair_viz(df[num_cols])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "methods = [\"pearson\", \"spearman\", \"kendall\"]\n",
    "for method in methods:\n",
    "    fz.corr_heatmap_viz(df[num_cols], method=method)\n",
    "    plt.show()\n",
    "    print(\"-\" * 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab Heatmap\n",
    "fz.crosstab_heatmap_viz(df, cat_cols, normalize=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"applicant_income\", cat_cols)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coapplicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"coapplicant_income\", cat_cols)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_amount\n",
    "fig, axs = fz.num_cat_viz(df, \"loan_amount\", cat_cols)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KDE-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"applicant_income\", cat_cols, kind=\"kde\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coapplicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"coapplicant_income\", cat_cols, kind=\"kde\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_amount\n",
    "fig, axs = fz.num_cat_viz(df, \"loan_amount\", cat_cols, kind=\"kde\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Point-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"applicant_income\", cat_cols, kind=\"point\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coapplicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"coapplicant_income\", cat_cols, kind=\"point\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_amount\n",
    "fig, axs = fz.num_cat_viz(df, \"loan_amount\", cat_cols, kind=\"point\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vs. Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab Heatmap\n",
    "fz.crosstab_heatmap_viz(df, cat_cols, [\"loan_status\"], \"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-plot\n",
    "fig, axs = fz.num_cat_viz(df, num_cols, \"loan_status\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE-plot\n",
    "fig, axs = fz.num_cat_viz(df, num_cols, \"loan_status\", kind=\"kde\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point-plot\n",
    "fig, axs = fz.num_cat_viz(df, num_cols, \"loan_status\", kind=\"point\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mulitvariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vs. Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Numerical - Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Scatter3d(\n",
    "    x=df[\"applicant_income\"],\n",
    "    y=df[\"coapplicant_income\"],\n",
    "    z=df[\"loan_amount\"],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=5),\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Applicant Income\",\n",
    "        yaxis_title=\"Coapplicant Income\",\n",
    "        zaxis_title=\"Loan Amount\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Numerical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "for feature in cat_cols:\n",
    "    sns.pairplot(df, vars=num_cols, hue=feature)\n",
    "    plt.show()\n",
    "    print(\"-\" * 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_num_cat_viz(x, y, categorical_features):\n",
    "    for feature in categorical_features:\n",
    "        sns.relplot(df, x=x, y=y, col=feature)\n",
    "        plt.show()\n",
    "        print(\"-\" * 118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_income & coapplicant_income\n",
    "num_num_cat_viz(\"applicant_income\", \"coapplicant_income\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_income & loan_amount\n",
    "num_num_cat_viz(\"applicant_income\", \"loan_amount\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coapplicant_income & loan_amount\n",
    "num_num_cat_viz(\"coapplicant_income\", \"loan_amount\", cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Categorical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vs. Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Numerical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars=num_cols, hue=\"loan_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relplot(df, numerical_features, categorical_feature):\n",
    "    for i, feature_i in enumerate(numerical_features):\n",
    "        for j, feature_j in enumerate(numerical_features[i + 1 :], start=i + 1):\n",
    "            sns.relplot(df, x=feature_i, y=feature_j, col=categorical_feature)\n",
    "            plt.show()\n",
    "            print(\"-\" * df[categorical_feature].nunique() * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relplot(df, num_cols, \"loan_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Categorical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It looks like people with a co-applicant income of 0 doesn't have a co-applicant. So, we should create a new feature called 'has_coapplicant'. For this feature, set the value to 'no' for individuals with a co-applicant income of 0, and 'yes' for those with a non-zero co-applicant income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_coapplicant\"] = np.where(df[\"coapplicant_income\"] == 0, \"no\", \"yes\")\n",
    "\n",
    "# Test\n",
    "df[\"has_coapplicant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending newly created features based on their feature type\n",
    "cat_cols.append(\"has_coapplicant\")\n",
    "\n",
    "# Test\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = fz.feature_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applicant_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig, axs = fz.feature_transform_viz(df[\"applicant_income\"], transformed_data)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ Plot\n",
    "fig, axs = fz.feature_transform_viz(df[\"applicant_income\"], transformed_data, kind=\"qq\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coapplicant_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig, axs = fz.feature_transform_viz(df[\"coapplicant_income\"], transformed_data)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ Plot\n",
    "fig, axs = fz.feature_transform_viz(\n",
    "    df[\"coapplicant_income\"], transformed_data, kind=\"qq\"\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loan_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig, axs = fz.feature_transform_viz(df[\"loan_amount\"], transformed_data)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ Plot\n",
    "fig, axs = fz.feature_transform_viz(df[\"loan_amount\"], transformed_data, kind=\"qq\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "- **applicant_income & loan_amount:** Quantile Transform normalizes the data effectively.  \n",
    "- **coapplicant_income:** Reciprocal Transform transforms coapplicant_income to follow a bimodal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"applicant_income\"] = transformed_data[\"Quantile\"][\"applicant_income\"]\n",
    "df[\"coapplicant_income\"] = transformed_data[\"Reciprocal\"][\"coapplicant_income\"]\n",
    "df[\"loan_amount\"] = transformed_data[\"Quantile\"][\"loan_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "fig, axs = fz.hist_box_viz(df[num_cols])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Handle missing values in categorical columns\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder expects datatypes of every value in a column to be the same\n",
    "X[cat_cols] = X[cat_cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store encoded feature names before encoding\n",
    "unique_values_in_cols = {}\n",
    "for col in cat_cols:\n",
    "    encoded_columns = []\n",
    "    for value in X[col].unique():\n",
    "        encoded_columns.append(f\"{col}_{value}\")\n",
    "    unique_values_in_cols[col] = encoded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. One-Hot Encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\", handle_unknown=\"ignore\")\n",
    "encoded_X_data = encoder.fit_transform(X[cat_cols])\n",
    "encoded_X_df = pd.DataFrame(encoded_X_data, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Concatenating encoded categorical features with the rest of the X\n",
    "X = pd.concat([X.drop(columns=cat_cols), encoded_X_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Impute missing values in numerical features using KNN imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "X = pd.DataFrame(knn_imputer.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Assign the missing value imputed numerical features back to df\n",
    "df[num_cols_with_nan] = X[num_cols_with_nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_categorical_imputer(X, y, clf_model):\n",
    "    X, y = X.copy(), y.copy()  # Avoid modifying the original X and y\n",
    "\n",
    "    y_notna = y.notna()  # Create a mask for non-missing values in y\n",
    "\n",
    "    # Split the data into training (non-missing) and test (missing) data\n",
    "    X, X_test = X[y_notna], X[~y_notna]\n",
    "    y_train, y_test = y[y_notna], y[~y_notna]\n",
    "\n",
    "    # Label encoding the target feature\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "\n",
    "    clf_model.fit(X, y_train)  # Train the model\n",
    "\n",
    "    y_pred = clf_model.predict(X_test)  # Predict on the test data (missing values)\n",
    "\n",
    "    # Inverse transform the predicted values to original labels\n",
    "    y_pred_inverse = le.inverse_transform(y_pred)\n",
    "\n",
    "    y[y_test.index] = y_pred_inverse  # Impute the missing target values\n",
    "\n",
    "    return y, clf_model, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_models = {}\n",
    "label_encoders = {}\n",
    "for col in cat_cols_with_nan:\n",
    "    df[col], clf_models[col], label_encoders[col] = advanced_categorical_imputer(\n",
    "        X.drop(columns=unique_values_in_cols[col], errors=\"ignore\"),\n",
    "        df[col],\n",
    "        ExtraTreesClassifier(random_state=42),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "    if df.isna().any().any():\n",
    "        print(\"There are still missing values in the DataFrame.\")\n",
    "    else:\n",
    "        print(\"There are no missing values left in the DataFrame.\")\n",
    "\n",
    "\n",
    "# Test\n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configurations\n",
    "with open(\"config/config_v2.toml\", \"r\") as file:\n",
    "    config_data = toml.load(file)\n",
    "\n",
    "num_cols, cat_cols = config_data[\"num\"][\"cols\"], config_data[\"cat\"][\"cols\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = df.drop(\"loan_status\", axis=1)\n",
    "y = df[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranformer for preprocessing data\n",
    "transformer = make_column_transformer(\n",
    "    (StandardScaler(), num_cols),\n",
    "    (OneHotEncoder(drop=\"first\", sparse_output=False), cat_cols),\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = transformer.fit_transform(X)\n",
    "\n",
    "# Test\n",
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling the dataset using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_transformed, y_resampled = smote.fit_resample(X_transformed, y)\n",
    "\n",
    "# Test\n",
    "print(X_transformed.shape, y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "unique_values, counts = np.unique(y_resampled, return_counts=True)\n",
    "\n",
    "# Print the counts of each class\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Class {value}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection (Before hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Trees\": DecisionTreeClassifier(),\n",
    "    \"Xgboost\": XGBClassifier(),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric functions\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"precision\": precision_score,\n",
    "    \"recall\": recall_score,\n",
    "    \"f1\": f1_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models_across_metrics(models, metrics, X, y, cv=5):\n",
    "    models_across_metrics = {metric: {} for metric in metrics}\n",
    "    for metric in metrics:\n",
    "        for model_name, model in models.items():\n",
    "            cv_scores = cross_val_score(model, X, y, cv=cv, scoring=metric)\n",
    "            cv_scores_mean = cv_scores.mean()\n",
    "            models_across_metrics[metric][model_name] = round(cv_scores_mean, 3)\n",
    "    return pd.DataFrame(models_across_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_across_metrics = eval_models_across_metrics(\n",
    "    models, metrics.keys(), X_transformed, y_resampled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_across_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "\n",
    "- After evaluating the metrics, I have decided to focus on the top 3 models (in terms of accuracy_score): Random Forest Classifier, Extra Trees Classifier, Xgboost Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define top models for further hyperparameter tuning\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Xgboost\": XGBClassifier(),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target\n",
    "X = df.drop(\"loan_status\", axis=1)\n",
    "y = df[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 200],\n",
    "        \"max_depth\": [None, 30],\n",
    "        \"min_samples_split\": [2, 10],\n",
    "        \"min_samples_leaf\": [1, 4],\n",
    "    },\n",
    "    \"Xgboost\": {\n",
    "        \"n_estimators\": [50, 200],\n",
    "        \"max_depth\": [3, 10],\n",
    "        \"learning_rate\": [0.01, 0.2],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.8, 1.0],\n",
    "        \"gamma\": [0, 0.2],\n",
    "    },\n",
    "    \"Extra Trees\": {\n",
    "        \"n_estimators\": [50, 200],\n",
    "        \"max_depth\": [None, 30],\n",
    "        \"min_samples_split\": [2, 10],\n",
    "        \"min_samples_leaf\": [1, 4],\n",
    "        \"bootstrap\": [True, False],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(models, param_grids, X, y):\n",
    "    best_params = {}\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Processing {model_name}...\")\n",
    "        param_grid = param_grids[model_name]\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            scoring=\"accuracy\",\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            verbose=1,\n",
    "        )\n",
    "        grid_search.fit(X, y)\n",
    "        best_params[model_name] = {\n",
    "            \"Best Parameters\": grid_search.best_params_,\n",
    "            \"Average accuracy score on the best parameters\": round(\n",
    "                grid_search.best_score_, 3\n",
    "            ),\n",
    "        }\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best hyperparameters on top models using GridSearchCV\n",
    "best_params = perform_grid_search(models, param_grids, X_transformed, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params\n",
    "\n",
    "# {'Random Forest': {'Best Parameters': {'max_depth': None,\n",
    "#    'min_samples_leaf': 1,\n",
    "#    'min_samples_split': 2,\n",
    "#    'n_estimators': 200},\n",
    "#   'Average accuracy score on the best parameters': 0.838},\n",
    "#  'Xgboost': {'Best Parameters': {'colsample_bytree': 0.8,\n",
    "#    'gamma': 0.2,\n",
    "#    'learning_rate': 0.2,\n",
    "#    'max_depth': 10,\n",
    "#    'n_estimators': 50,\n",
    "#    'subsample': 1.0},\n",
    "#   'Average accuracy score on the best parameters': 0.826},\n",
    "#  'Extra Trees': {'Best Parameters': {'bootstrap': True,\n",
    "#    'max_depth': 30,\n",
    "#    'min_samples_leaf': 1,\n",
    "#    'min_samples_split': 2,\n",
    "#    'n_estimators': 200},\n",
    "#   'Average accuracy score on the best parameters': 0.84}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define top models with best hyperparameters\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        **best_params[\"Random Forest\"][\"Best Parameters\"]\n",
    "    ),\n",
    "    \"Xgboost\": XGBClassifier(**best_params[\"Xgboost\"][\"Best Parameters\"]),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(\n",
    "        **best_params[\"Extra Trees\"][\"Best Parameters\"]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing top models across metrics after hyperparameter tuning\n",
    "models_across_metrics = eval_models_across_metrics(\n",
    "    models, metrics.keys(), X_transformed, y_resampled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_across_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "for model_name, model in models.items():\n",
    "    estimators.append((model_name, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_voting_clf(estimators, X, y, cv=5):\n",
    "    # Create a voting classifier (hard voting)\n",
    "    voting_clf_hard = VotingClassifier(estimators=estimators, voting=\"hard\")\n",
    "\n",
    "    # Create a voting classifier (soft voting)\n",
    "    voting_clf_soft = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "\n",
    "    # Apply cross-validation\n",
    "    cv_scores_h = cross_val_score(voting_clf_hard, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    cv_scores_s = cross_val_score(voting_clf_soft, X, y, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "    accuracy_results = {}\n",
    "\n",
    "    accuracy_results[\"Hard Margin\"] = round(cv_scores_h.mean(), 3)\n",
    "    accuracy_results[\"Soft Margin\"] = round(cv_scores_s.mean(), 3)\n",
    "\n",
    "    return accuracy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on hard and soft margin voting classifiers\n",
    "accuracy = eval_voting_clf(estimators, X_transformed, y_resampled)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best model\n",
    "voting_clf = VotingClassifier(estimators, voting=\"hard\")\n",
    "voting_clf.fit(X_transformed, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),  # Step 1: Standardize the data\n",
    "    PCA(n_components=2),  # Step 2: Apply PCA\n",
    "    LogisticRegression(),  # Step 3: Train a logistic regression model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "target_col = \"loan_status\"\n",
    "df = df[num_cols + cat_cols + [target_col]]\n",
    "\n",
    "# Test\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "pipe = make_pipeline((transformer), (\"model\", voting_clf))\n",
    "\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Machine Learning model\n",
    "joblib.dump(voting_clf, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical measures\n",
    "df[[\"has_coapplicant\"]].describe().T\n",
    "\n",
    "# Countplot\n",
    "sns.countplot(x=df[\"has_coapplicant\"])\n",
    "plt.show()\n",
    "\n",
    "# Heatmap\n",
    "fz.crosstab_heatmap_viz(df, [\"loan_status\"], [\"has_coapplicant\"], \"both\")\n",
    "\n",
    "# Heatmap\n",
    "fz.crosstab_heatmap_viz(df, cat_cols, [\"has_coapplicant\"], \"both\")\n",
    "\n",
    "# Point plot\n",
    "fig, axs = fz.num_cat_viz(df, num_cols, \"has_coapplicant\", kind=\"point\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export config data\n",
    "config_data = {\n",
    "    \"column_names\": column_names,\n",
    "    \"num\": {\"cols\": num_cols, \"nan\": num_cols_with_nan},\n",
    "    \"cat\": {\"cols\": cat_cols, \"nan\": cat_cols_with_nan},\n",
    "    \"target_col\": target_col,\n",
    "}\n",
    "\n",
    "with open(\"src/loan_sanction_prediction/config.yaml\", \"w\") as file:\n",
    "    yaml.dump(config_data, file, default_flow_style=False)\n",
    "\n",
    "# Export dataset\n",
    "fz.export(df, \"../data/interim/cleaned_train_data_v1.csv\", force_overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Format columns...\")\n",
    "try:\n",
    "    df = df[num_cols + cat_cols + target_col]\n",
    "    log.success(f\"Successfully formatted columns: {df.columns.to_list()}\")\n",
    "except Exception:\n",
    "    log.exception(\"Failed to format columns\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
