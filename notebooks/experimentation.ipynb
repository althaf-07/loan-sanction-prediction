{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flash as fz\n",
    "import joblib\n",
    "import klib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    OneHotEncoder,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Assessment and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>married</th>\n",
       "      <th>dependents</th>\n",
       "      <th>education</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>applicant_income</th>\n",
       "      <th>coapplicant_income</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_amount_term</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>property_area</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>2333</td>\n",
       "      <td>2417.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>graduate</td>\n",
       "      <td>yes</td>\n",
       "      <td>11500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>645</td>\n",
       "      <td>3683.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rural</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>4750</td>\n",
       "      <td>2333.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>not_graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>1993</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>semiurban</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>5000</td>\n",
       "      <td>3667.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>semiurban</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>9083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>semiurban</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>not_graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2894</td>\n",
       "      <td>2792.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rural</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>2130</td>\n",
       "      <td>6666.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>semiurban</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>8750</td>\n",
       "      <td>4996.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rural</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender married dependents     education self_employed  applicant_income  \\\n",
       "0      male     yes          0      graduate            no              2333   \n",
       "1    female     yes          1      graduate           yes             11500   \n",
       "2    female      no          0      graduate            no               645   \n",
       "3      male     yes          0      graduate            no              4750   \n",
       "4      male     yes          2  not_graduate            no              1993   \n",
       "..      ...     ...        ...           ...           ...               ...   \n",
       "486    male     yes          2      graduate            no              5000   \n",
       "487    male     yes          0      graduate            no              9083   \n",
       "488    male     yes          0  not_graduate           NaN              2894   \n",
       "489    male     yes          0      graduate            no              2130   \n",
       "490    male     yes         3+      graduate            no              8750   \n",
       "\n",
       "     coapplicant_income  loan_amount  loan_amount_term  credit_history  \\\n",
       "0                2417.0        136.0             360.0             1.0   \n",
       "1                   0.0        286.0             360.0             0.0   \n",
       "2                3683.0        113.0             480.0             1.0   \n",
       "3                2333.0        130.0             360.0             1.0   \n",
       "4                1625.0        113.0             180.0             1.0   \n",
       "..                  ...          ...               ...             ...   \n",
       "486              3667.0        236.0             360.0             1.0   \n",
       "487                 0.0        228.0             360.0             1.0   \n",
       "488              2792.0        155.0             360.0             1.0   \n",
       "489              6666.0         70.0             180.0             1.0   \n",
       "490              4996.0        130.0             360.0             1.0   \n",
       "\n",
       "    property_area loan_status  \n",
       "0           urban         yes  \n",
       "1           urban          no  \n",
       "2           rural         yes  \n",
       "3           urban         yes  \n",
       "4       semiurban         yes  \n",
       "..            ...         ...  \n",
       "486     semiurban         yes  \n",
       "487     semiurban         yes  \n",
       "488         rural         yes  \n",
       "489     semiurban          no  \n",
       "490         rural         yes  \n",
       "\n",
       "[491 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['graduate', 'not graduate'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>married</th>\n",
       "      <th>dependents</th>\n",
       "      <th>education</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>applicant_income</th>\n",
       "      <th>coapplicant_income</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_amount_term</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>property_area</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>23803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rural</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>7933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>not graduate</td>\n",
       "      <td>yes</td>\n",
       "      <td>2609</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rural</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>not graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>2889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>4000</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>semiurban</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>8334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>semiurban</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>3173</td>\n",
       "      <td>3021.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>not graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>2600</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>semiurban</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>5819</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rural</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>graduate</td>\n",
       "      <td>yes</td>\n",
       "      <td>5266</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>semiurban</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender married  dependents     education self_employed  applicant_income  \\\n",
       "0      NaN     yes         3.0      graduate            no             23803   \n",
       "1     male     yes         0.0      graduate            no              7933   \n",
       "2     male     yes         0.0  not graduate           yes              2609   \n",
       "3     male     yes         2.0  not graduate            no              2889   \n",
       "4     male     yes         3.0      graduate            no              4000   \n",
       "..     ...     ...         ...           ...           ...               ...   \n",
       "118   male     yes         0.0      graduate            no              8334   \n",
       "119   male     yes         0.0      graduate            no              3173   \n",
       "120   male     yes         0.0  not graduate            no              2600   \n",
       "121   male     yes         2.0      graduate            no              5819   \n",
       "122   male     yes         3.0      graduate           yes              5266   \n",
       "\n",
       "     coapplicant_income  loan_amount  loan_amount_term  credit_history  \\\n",
       "0                   0.0        370.0             360.0             1.0   \n",
       "1                   0.0        275.0             360.0             1.0   \n",
       "2                3449.0        165.0             180.0             0.0   \n",
       "3                   0.0         45.0             180.0             0.0   \n",
       "4                7750.0        290.0             360.0             1.0   \n",
       "..                  ...          ...               ...             ...   \n",
       "118                 0.0        160.0             360.0             1.0   \n",
       "119              3021.0        137.0             360.0             1.0   \n",
       "120              1911.0        116.0             360.0             0.0   \n",
       "121              5000.0        120.0             360.0             1.0   \n",
       "122              1774.0        187.0             360.0             1.0   \n",
       "\n",
       "    property_area loan_status  \n",
       "0           rural           y  \n",
       "1           urban           n  \n",
       "2           rural           n  \n",
       "3           urban           n  \n",
       "4       semiurban           n  \n",
       "..            ...         ...  \n",
       "118     semiurban           n  \n",
       "119         urban           y  \n",
       "120     semiurban           n  \n",
       "121         rural           y  \n",
       "122     semiurban           y  \n",
       "\n",
       "[123 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/processed/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/raw/loan_sanction_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIntCastingNaNError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdependents\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/machine-learning/loan-sanction-prediction/.venv/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6637\u001b[39m     results = [\n\u001b[32m   6638\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6639\u001b[39m     ]\n\u001b[32m   6641\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6642\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6643\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6644\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/machine-learning/loan-sanction-prediction/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    428\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/machine-learning/loan-sanction-prediction/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/machine-learning/loan-sanction-prediction/.venv/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    755\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    756\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    762\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/machine-learning/loan-sanction-prediction/.venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/machine-learning/loan-sanction-prediction/.venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/machine-learning/loan-sanction-prediction/.venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:101\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.ensure_string_array(\n\u001b[32m     97\u001b[39m         arr, skipna=skipna, convert_na_value=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     98\u001b[39m     ).reshape(shape)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m np.issubdtype(arr.dtype, np.floating) \u001b[38;5;129;01mand\u001b[39;00m dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lib.is_np_dtype(dtype, \u001b[33m\"\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/machine-learning/loan-sanction-prediction/.venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:145\u001b[39m, in \u001b[36m_astype_float_to_int_nansafe\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(values).all():\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[32m    146\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    147\u001b[39m     )\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype.kind == \u001b[33m\"\u001b[39m\u001b[33mu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    149\u001b[39m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values >= \u001b[32m0\u001b[39m).all():\n",
      "\u001b[31mIntCastingNaNError\u001b[39m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "df[\"dependents\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand structure of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless features\n",
    "useless_features = [\"Loan_ID\"]\n",
    "df.drop(columns=useless_features, inplace=True)\n",
    "\n",
    "# Test\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "df = klib.clean_column_names(df)\n",
    "\n",
    "# Test\n",
    "column_names = df.columns.tolist()\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate data points\n",
    "def check_duplicates(df):\n",
    "    if df.duplicated().any():\n",
    "        return df[df.duplicated(keep=False)]\n",
    "    return \"There are no duplicate data points in the dataset.\"\n",
    "\n",
    "\n",
    "check_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical, categorical, and other features from the dataset\n",
    "num_cols, cat_cols, other_cols = fz.extract_features(\n",
    "    df, \"all\", ignore_cols=[\"loan_status\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print numerical features of dataset\n",
    "df[num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print categorical features of dataset\n",
    "df[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dependents\"] = df[\"dependents\"].str.replace(r\"\\+$\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"loan_status\"] = df[\"loan_status\"].replace({\"Y\": \"yes\", \"N\": \"no\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datatype of features\n",
    "# df['applicant_income'] = df['applicant_income'].astype(float)\n",
    "df[\"dependents\"] = df[\"dependents\"].astype(\"Int64\")\n",
    "df[\"loan_amount_term\"] = df[\"loan_amount_term\"].astype(\"Int64\")\n",
    "df[\"credit_history\"] = df[\"credit_history\"].astype(\"Int64\")\n",
    "# Convert categorical features' data type to category\n",
    "# This will be helpful while doing analysis\n",
    "df[cat_cols] = df[cat_cols].astype(\"category\")\n",
    "\n",
    "# Test\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features\n",
    "num_nan_pct = fz.calc_nan_values(df[num_cols])\n",
    "num_cols_with_nan = num_nan_pct.index.tolist()\n",
    "\n",
    "print(num_nan_pct)  # Percentage of missing values in numerical features\n",
    "print(num_cols_with_nan)  # Numerical features with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "cat_nan_pct = fz.calc_nan_values(df[cat_cols])\n",
    "cat_cols_with_nan = cat_nan_pct.index.tolist()\n",
    "\n",
    "print(cat_nan_pct)  # Percentage of missing values in categorical features\n",
    "print(cat_cols_with_nan)  # Categorical features with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the target column contains any missing values\n",
    "df[\"loan_status\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of missing values to determine the type of missing values\n",
    "fig, axs = fz.nan_value_viz(df[num_cols_with_nan + cat_cols_with_nan])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical measures\n",
    "df[num_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical moments\n",
    "fz.stats_moments(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histogram & boxplot\n",
    "fig, axs = fz.hist_box_viz(df[num_cols])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical measures\n",
    "df[cat_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplots\n",
    "fig, axs = fz.count_viz(df[cat_cols])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"loan_status\"].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(\n",
    "    df[\"loan_status\"].value_counts(),\n",
    "    labels=df[\"loan_status\"].unique(),\n",
    "    autopct=\"%0.2f%%\",\n",
    "    shadow=True,\n",
    "    explode=(0, 0.1),\n",
    "    counterclock=False,\n",
    "    colors=[\"lime\", \"cyan\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vs. Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "grid = fz.pair_viz(df[num_cols])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "methods = [\"pearson\", \"spearman\", \"kendall\"]\n",
    "for method in methods:\n",
    "    fz.corr_heatmap_viz(df[num_cols], method=method)\n",
    "    plt.show()\n",
    "    print(\"-\" * 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab Heatmap\n",
    "fz.crosstab_heatmap_viz(df, cat_cols, normalize=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"applicant_income\", cat_cols)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coapplicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"coapplicant_income\", cat_cols)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_amount\n",
    "fig, axs = fz.num_cat_viz(df, \"loan_amount\", cat_cols)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KDE-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"applicant_income\", cat_cols, kind=\"kde\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coapplicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"coapplicant_income\", cat_cols, kind=\"kde\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_amount\n",
    "fig, axs = fz.num_cat_viz(df, \"loan_amount\", cat_cols, kind=\"kde\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Point-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"applicant_income\", cat_cols, kind=\"point\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coapplicant_income\n",
    "fig, axs = fz.num_cat_viz(df, \"coapplicant_income\", cat_cols, kind=\"point\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_amount\n",
    "fig, axs = fz.num_cat_viz(df, \"loan_amount\", cat_cols, kind=\"point\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vs. Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab Heatmap\n",
    "fz.crosstab_heatmap_viz(df, cat_cols, [\"loan_status\"], \"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-plot\n",
    "fig, axs = fz.num_cat_viz(df, num_cols, \"loan_status\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE-plot\n",
    "fig, axs = fz.num_cat_viz(df, num_cols, \"loan_status\", kind=\"kde\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point-plot\n",
    "fig, axs = fz.num_cat_viz(df, num_cols, \"loan_status\", kind=\"point\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mulitvariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vs. Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Numerical - Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Scatter3d(\n",
    "    x=df[\"applicant_income\"],\n",
    "    y=df[\"coapplicant_income\"],\n",
    "    z=df[\"loan_amount\"],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=5),\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Applicant Income\",\n",
    "        yaxis_title=\"Coapplicant Income\",\n",
    "        zaxis_title=\"Loan Amount\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Numerical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "for feature in cat_cols:\n",
    "    sns.pairplot(df, vars=num_cols, hue=feature)\n",
    "    plt.show()\n",
    "    print(\"-\" * 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_num_cat_viz(x, y, categorical_features):\n",
    "    for feature in categorical_features:\n",
    "        sns.relplot(df, x=x, y=y, col=feature)\n",
    "        plt.show()\n",
    "        print(\"-\" * 118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_income & coapplicant_income\n",
    "num_num_cat_viz(\"applicant_income\", \"coapplicant_income\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_income & loan_amount\n",
    "num_num_cat_viz(\"applicant_income\", \"loan_amount\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coapplicant_income & loan_amount\n",
    "num_num_cat_viz(\"coapplicant_income\", \"loan_amount\", cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Categorical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vs. Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Numerical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars=num_cols, hue=\"loan_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relplot(df, numerical_features, categorical_feature):\n",
    "    for i, feature_i in enumerate(numerical_features):\n",
    "        for j, feature_j in enumerate(numerical_features[i + 1 :], start=i + 1):\n",
    "            sns.relplot(df, x=feature_i, y=feature_j, col=categorical_feature)\n",
    "            plt.show()\n",
    "            print(\"-\" * df[categorical_feature].nunique() * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relplot(df, num_cols, \"loan_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical - Categorical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It looks like people with a co-applicant income of 0 doesn't have a co-applicant. So, we should create a new feature called 'has_coapplicant'. For this feature, set the value to 'no' for individuals with a co-applicant income of 0, and 'yes' for those with a non-zero co-applicant income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_coapplicant\"] = np.where(df[\"coapplicant_income\"] == 0, \"no\", \"yes\")\n",
    "\n",
    "# Test\n",
    "df[\"has_coapplicant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending newly created features based on their feature type\n",
    "cat_cols.append(\"has_coapplicant\")\n",
    "\n",
    "# Test\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = fz.feature_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applicant_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig, axs = fz.feature_transform_viz(df[\"applicant_income\"], transformed_data)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ Plot\n",
    "fig, axs = fz.feature_transform_viz(df[\"applicant_income\"], transformed_data, kind=\"qq\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coapplicant_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig, axs = fz.feature_transform_viz(df[\"coapplicant_income\"], transformed_data)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ Plot\n",
    "fig, axs = fz.feature_transform_viz(\n",
    "    df[\"coapplicant_income\"], transformed_data, kind=\"qq\"\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loan_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig, axs = fz.feature_transform_viz(df[\"loan_amount\"], transformed_data)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ Plot\n",
    "fig, axs = fz.feature_transform_viz(df[\"loan_amount\"], transformed_data, kind=\"qq\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "- **applicant_income & loan_amount:** Quantile Transform normalizes the data effectively.  \n",
    "- **coapplicant_income:** Reciprocal Transform transforms coapplicant_income to follow a bimodal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"applicant_income\"] = transformed_data[\"Quantile\"][\"applicant_income\"]\n",
    "df[\"coapplicant_income\"] = transformed_data[\"Reciprocal\"][\"coapplicant_income\"]\n",
    "df[\"loan_amount\"] = transformed_data[\"Quantile\"][\"loan_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "fig, axs = fz.hist_box_viz(df[num_cols])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Handle missing values in categorical columns\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder expects datatypes of every value in a column to be the same\n",
    "X[cat_cols] = X[cat_cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store encoded feature names before encoding\n",
    "unique_values_in_cols = {}\n",
    "for col in cat_cols:\n",
    "    encoded_columns = []\n",
    "    for value in X[col].unique():\n",
    "        encoded_columns.append(f\"{col}_{value}\")\n",
    "    unique_values_in_cols[col] = encoded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. One-Hot Encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\", handle_unknown=\"ignore\")\n",
    "encoded_X_data = encoder.fit_transform(X[cat_cols])\n",
    "encoded_X_df = pd.DataFrame(encoded_X_data, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Concatenating encoded categorical features with the rest of the X\n",
    "X = pd.concat([X.drop(columns=cat_cols), encoded_X_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Impute missing values in numerical features using KNN imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "X = pd.DataFrame(knn_imputer.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Assign the missing value imputed numerical features back to df\n",
    "df[num_cols_with_nan] = X[num_cols_with_nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_categorical_imputer(X, y, clf_model):\n",
    "    X, y = X.copy(), y.copy()  # Avoid modifying the original X and y\n",
    "\n",
    "    y_notna = y.notna()  # Create a mask for non-missing values in y\n",
    "\n",
    "    # Split the data into training (non-missing) and test (missing) data\n",
    "    X, X_test = X[y_notna], X[~y_notna]\n",
    "    y_train, y_test = y[y_notna], y[~y_notna]\n",
    "\n",
    "    # Label encoding the target feature\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "\n",
    "    clf_model.fit(X, y_train)  # Train the model\n",
    "\n",
    "    y_pred = clf_model.predict(X_test)  # Predict on the test data (missing values)\n",
    "\n",
    "    # Inverse transform the predicted values to original labels\n",
    "    y_pred_inverse = le.inverse_transform(y_pred)\n",
    "\n",
    "    y[y_test.index] = y_pred_inverse  # Impute the missing target values\n",
    "\n",
    "    return y, clf_model, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_models = {}\n",
    "label_encoders = {}\n",
    "for col in cat_cols_with_nan:\n",
    "    df[col], clf_models[col], label_encoders[col] = advanced_categorical_imputer(\n",
    "        X.drop(columns=unique_values_in_cols[col], errors=\"ignore\"),\n",
    "        df[col],\n",
    "        ExtraTreesClassifier(random_state=42),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "    if df.isna().any().any():\n",
    "        print(\"There are still missing values in the DataFrame.\")\n",
    "    else:\n",
    "        print(\"There are no missing values left in the DataFrame.\")\n",
    "\n",
    "\n",
    "# Test\n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configurations\n",
    "with open(\"config/config_v2.toml\", \"r\") as file:\n",
    "    config_data = toml.load(file)\n",
    "\n",
    "num_cols, cat_cols = config_data[\"num\"][\"cols\"], config_data[\"cat\"][\"cols\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = df.drop(\"loan_status\", axis=1)\n",
    "y = df[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranformer for preprocessing data\n",
    "transformer = make_column_transformer(\n",
    "    (StandardScaler(), num_cols),\n",
    "    (OneHotEncoder(drop=\"first\", sparse_output=False), cat_cols),\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = transformer.fit_transform(X)\n",
    "\n",
    "# Test\n",
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling the dataset using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_transformed, y_resampled = smote.fit_resample(X_transformed, y)\n",
    "\n",
    "# Test\n",
    "print(X_transformed.shape, y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "unique_values, counts = np.unique(y_resampled, return_counts=True)\n",
    "\n",
    "# Print the counts of each class\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Class {value}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection (Before hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Trees\": DecisionTreeClassifier(),\n",
    "    \"Xgboost\": XGBClassifier(),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric functions\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"precision\": precision_score,\n",
    "    \"recall\": recall_score,\n",
    "    \"f1\": f1_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models_across_metrics(models, metrics, X, y, cv=5):\n",
    "    models_across_metrics = {metric: {} for metric in metrics}\n",
    "    for metric in metrics:\n",
    "        for model_name, model in models.items():\n",
    "            cv_scores = cross_val_score(model, X, y, cv=cv, scoring=metric)\n",
    "            cv_scores_mean = cv_scores.mean()\n",
    "            models_across_metrics[metric][model_name] = round(cv_scores_mean, 3)\n",
    "    return pd.DataFrame(models_across_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_across_metrics = eval_models_across_metrics(\n",
    "    models, metrics.keys(), X_transformed, y_resampled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_across_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "\n",
    "- After evaluating the metrics, I have decided to focus on the top 3 models (in terms of accuracy_score): Random Forest Classifier, Extra Trees Classifier, Xgboost Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define top models for further hyperparameter tuning\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Xgboost\": XGBClassifier(),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target\n",
    "X = df.drop(\"loan_status\", axis=1)\n",
    "y = df[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 200],\n",
    "        \"max_depth\": [None, 30],\n",
    "        \"min_samples_split\": [2, 10],\n",
    "        \"min_samples_leaf\": [1, 4],\n",
    "    },\n",
    "    \"Xgboost\": {\n",
    "        \"n_estimators\": [50, 200],\n",
    "        \"max_depth\": [3, 10],\n",
    "        \"learning_rate\": [0.01, 0.2],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.8, 1.0],\n",
    "        \"gamma\": [0, 0.2],\n",
    "    },\n",
    "    \"Extra Trees\": {\n",
    "        \"n_estimators\": [50, 200],\n",
    "        \"max_depth\": [None, 30],\n",
    "        \"min_samples_split\": [2, 10],\n",
    "        \"min_samples_leaf\": [1, 4],\n",
    "        \"bootstrap\": [True, False],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(models, param_grids, X, y):\n",
    "    best_params = {}\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Processing {model_name}...\")\n",
    "        param_grid = param_grids[model_name]\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            scoring=\"accuracy\",\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            verbose=1,\n",
    "        )\n",
    "        grid_search.fit(X, y)\n",
    "        best_params[model_name] = {\n",
    "            \"Best Parameters\": grid_search.best_params_,\n",
    "            \"Average accuracy score on the best parameters\": round(\n",
    "                grid_search.best_score_, 3\n",
    "            ),\n",
    "        }\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best hyperparameters on top models using GridSearchCV\n",
    "best_params = perform_grid_search(models, param_grids, X_transformed, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params\n",
    "\n",
    "# {'Random Forest': {'Best Parameters': {'max_depth': None,\n",
    "#    'min_samples_leaf': 1,\n",
    "#    'min_samples_split': 2,\n",
    "#    'n_estimators': 200},\n",
    "#   'Average accuracy score on the best parameters': 0.838},\n",
    "#  'Xgboost': {'Best Parameters': {'colsample_bytree': 0.8,\n",
    "#    'gamma': 0.2,\n",
    "#    'learning_rate': 0.2,\n",
    "#    'max_depth': 10,\n",
    "#    'n_estimators': 50,\n",
    "#    'subsample': 1.0},\n",
    "#   'Average accuracy score on the best parameters': 0.826},\n",
    "#  'Extra Trees': {'Best Parameters': {'bootstrap': True,\n",
    "#    'max_depth': 30,\n",
    "#    'min_samples_leaf': 1,\n",
    "#    'min_samples_split': 2,\n",
    "#    'n_estimators': 200},\n",
    "#   'Average accuracy score on the best parameters': 0.84}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define top models with best hyperparameters\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        **best_params[\"Random Forest\"][\"Best Parameters\"]\n",
    "    ),\n",
    "    \"Xgboost\": XGBClassifier(**best_params[\"Xgboost\"][\"Best Parameters\"]),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(\n",
    "        **best_params[\"Extra Trees\"][\"Best Parameters\"]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing top models across metrics after hyperparameter tuning\n",
    "models_across_metrics = eval_models_across_metrics(\n",
    "    models, metrics.keys(), X_transformed, y_resampled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_across_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "for model_name, model in models.items():\n",
    "    estimators.append((model_name, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_voting_clf(estimators, X, y, cv=5):\n",
    "    # Create a voting classifier (hard voting)\n",
    "    voting_clf_hard = VotingClassifier(estimators=estimators, voting=\"hard\")\n",
    "\n",
    "    # Create a voting classifier (soft voting)\n",
    "    voting_clf_soft = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "\n",
    "    # Apply cross-validation\n",
    "    cv_scores_h = cross_val_score(voting_clf_hard, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    cv_scores_s = cross_val_score(voting_clf_soft, X, y, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "    accuracy_results = {}\n",
    "\n",
    "    accuracy_results[\"Hard Margin\"] = round(cv_scores_h.mean(), 3)\n",
    "    accuracy_results[\"Soft Margin\"] = round(cv_scores_s.mean(), 3)\n",
    "\n",
    "    return accuracy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on hard and soft margin voting classifiers\n",
    "accuracy = eval_voting_clf(estimators, X_transformed, y_resampled)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best model\n",
    "voting_clf = VotingClassifier(estimators, voting=\"hard\")\n",
    "voting_clf.fit(X_transformed, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),  # Step 1: Standardize the data\n",
    "    PCA(n_components=2),  # Step 2: Apply PCA\n",
    "    LogisticRegression(),  # Step 3: Train a logistic regression model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "target_col = \"loan_status\"\n",
    "df = df[num_cols + cat_cols + [target_col]]\n",
    "\n",
    "# Test\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "pipe = make_pipeline((transformer), (\"model\", voting_clf))\n",
    "\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Machine Learning model\n",
    "joblib.dump(voting_clf, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical measures\n",
    "df[[\"has_coapplicant\"]].describe().T\n",
    "\n",
    "# Countplot\n",
    "sns.countplot(x=df[\"has_coapplicant\"])\n",
    "plt.show()\n",
    "\n",
    "# Heatmap\n",
    "fz.crosstab_heatmap_viz(df, [\"loan_status\"], [\"has_coapplicant\"], \"both\")\n",
    "\n",
    "# Heatmap\n",
    "fz.crosstab_heatmap_viz(df, cat_cols, [\"has_coapplicant\"], \"both\")\n",
    "\n",
    "# Point plot\n",
    "fig, axs = fz.num_cat_viz(df, num_cols, \"has_coapplicant\", kind=\"point\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export config data\n",
    "config_data = {\n",
    "    \"column_names\": column_names,\n",
    "    \"num\": {\"cols\": num_cols, \"nan\": num_cols_with_nan},\n",
    "    \"cat\": {\"cols\": cat_cols, \"nan\": cat_cols_with_nan},\n",
    "    \"target_col\": target_col,\n",
    "}\n",
    "\n",
    "with open(\"src/loan_sanction_prediction/config.yaml\", \"w\") as file:\n",
    "    yaml.dump(config_data, file, default_flow_style=False)\n",
    "\n",
    "# Export dataset\n",
    "fz.export(df, \"../data/interim/cleaned_train_data_v1.csv\", force_overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Format columns...\")\n",
    "try:\n",
    "    df = df[num_cols + cat_cols + target_col]\n",
    "    log.success(f\"Successfully formatted columns: {df.columns.to_list()}\")\n",
    "except Exception:\n",
    "    log.exception(\"Failed to format columns\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
